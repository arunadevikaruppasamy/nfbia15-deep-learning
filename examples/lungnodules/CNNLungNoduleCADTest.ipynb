{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains the code necessary to evaluate the performance of a convolutional neural network used in the false positive reduction step of a CAD system for pulmonary nodule detection.\n",
    "The set of candidates is given.\n",
    "\n",
    "Two configurations are considered:\n",
    "- a network that processes one view of the nodule\n",
    "- a network that processes three views of the nodule.\n",
    "\n",
    "The two networks are evaluated on 1/5 of the publicly available <a href=\"https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI\">LIDC-IDRI</a> data set in a cross-validation fashion (although only one of the five folds is considered in this notebook).\n",
    "\n",
    "\n",
    "### Theano\n",
    "The code in this notebook is based on the Theano library.\n",
    "- For information on Theano, check this: http://deeplearning.net/software/theano/\n",
    "- For instructions on how to install Theano, follow this: http://deeplearning.net/software/theano/install.html#install\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the libraries that we will be using in this example.\n",
    "Most of thse libraries can be installed by simply installing a distribution of <a href=\"https://store.continuum.io/cshop/anaconda/\">Anaconda</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import csv\n",
    "import cPickle\n",
    "import theano\n",
    "import math\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "projectDir = '/home/user/nfbia15-deep-learning/examples/lungnodules/' # <-- set this local folder\n",
    "\n",
    "srng = RandomStreams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in the convnet\n",
    "The following functions implement techniques required by the convolutional network.\n",
    "The following are the most important ones:\n",
    "\n",
    "- <a href=\"http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\">Dropout</a> \n",
    "\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Multinomial_logistic_regression\">Softmax</a>  \n",
    "\n",
    "- <a href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\">ReLU</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 'x')) # 0 < e_x <= 1\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 'x')\n",
    "\n",
    "def rectify(X):\n",
    "    # ReLU non linearity\n",
    "    return T.maximum(X, 0.)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function getDataset loads the data set from a numpy npz file.\n",
    "The file contains a field X for data and a field y for labels.\n",
    "Additionally, for the specific case of lung nodules, the position (in world coordinates) of the nodule and the seriesUID of the image can be loaded by setting the flag allInfo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataset(datasetPath, allInfo = False):\n",
    "    npzFile = np.load(datasetPath)\n",
    "    X = npzFile['X']\n",
    "    y = npzFile['y']\n",
    "    if allInfo is True:\n",
    "        pos = npzFile['pos']\n",
    "        image = npzFile['img']\n",
    "        return X,y,pos,image\n",
    "    else:\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "The <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\">Receiver Operator Characteristic curve (ROC)</a> is a useful tool for evaluating the performance of a binary classification problem such as nodule detection (classification of nodules versus non nodules).\n",
    "In this notebook, we use the function implemented in the scikit-learn library.\n",
    "The input file is a csv file where the classification results are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeROC(inputfilename, figuretitle):\n",
    "    h = open(inputfilename,'rb')\n",
    "    csvreader = csv.reader(h)\n",
    "    ytest = []; preds = []\n",
    "    first = True\n",
    "    for row in csvreader:\n",
    "        if first:\n",
    "            groundtruth_idx = row.index('o_0')\n",
    "            prediction_idx = row.index('o_2')\n",
    "            first = False\n",
    "        else:\n",
    "            ytest.append(float(row[groundtruth_idx]))\n",
    "            preds.append(float(row[prediction_idx]))\n",
    "    # compute ROC curve\n",
    "    fpr, tpr, _ = metrics.roc_curve(ytest, preds)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    # figure\n",
    "    fig = plt.figure('ROC')\n",
    "    plt.title(figuretitle)\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.gca().set_aspect(1.0)\n",
    "    plt.plot([0.0, 1.0],[0.0, 1.0],'k')\n",
    "    plt.xlabel('1 - specificity')\n",
    "    plt.ylabel('sensitivity')\n",
    "    ax = fig.gca(); ax.set_aspect('equal')\n",
    "    ax = fig.gca()\n",
    "    ax.set_xticks(np.arange(0.0,1.1,0.1))\n",
    "    ax.set_yticks(np.arange(0.0,1.1,0.1))\n",
    "    plt.grid()\n",
    "    plt.axis((0,1,0,1))\n",
    "    rocCurve, = plt.plot(fpr, tpr, linewidth=3)\n",
    "    plt.legend([rocCurve],['AUC = '+str(round(auc,4))[:5]+''],loc=4,prop={'size':12})\n",
    "    print 'AUC = '+str(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FROC curve\n",
    "The <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2776072/\">Free-Response ROC curve (FROC)</a> shows the performance in terms of sensitivity as a function of the number of false positive per scan.\n",
    "It is a useful tool to understand the behaviour of the CAD system, as well as to set an operating point (by picking the threshold that corresponds to the desired amount of false positives per scan).\n",
    "The input for this function is the same csv file used for the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeFROC(inputfilename, figuretitle, candidateDetectionSensitivity, datafilename, npoints=np.inf):\n",
    "    # collect number of cases\n",
    "    fh = open(inputfilename,'rb')\n",
    "    csvreader = csv.reader(fh)\n",
    "    # get indexes from the header\n",
    "    header = csvreader.next()\n",
    "    fh.seek(0)\n",
    "    seriesuid_idx = header.index('i_seriesuid')\n",
    "    groundtruth_idx = header.index('o_0')\n",
    "    prediction_idx = header.index('o_2')\n",
    "    seriesuids = []\n",
    "    thresholds = []\n",
    "    first = True\n",
    "    for csvrow in csvreader:\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            seriesuids.append(csvrow[seriesuid_idx])\n",
    "            thresholds.append(float(csvrow[prediction_idx]))\n",
    "    fh.seek(0)\n",
    "    # remove duplicates\n",
    "    unique_seriesuids = list(set(seriesuids))\n",
    "    thresholds = sorted(list(set(thresholds)))\n",
    "    print str(len(unique_seriesuids))+' scans found'\n",
    "    # take npoints values of threholds\n",
    "    n = min(npoints, len(thresholds))\n",
    "    pts = range(0,len(thresholds),int(float(len(thresholds))/float(n)))\n",
    "    thresholds = [thresholds[i] for i in pts]\n",
    "    thresholds.append(1.0)\n",
    "    # fill in structured data\n",
    "    nlines = len(list(csvreader))-1\n",
    "    groundtruth_array = np.zeros((nlines, 1))\n",
    "    predictions_array = np.zeros((nlines, 1))\n",
    "    seriesuids_array = np.zeros((nlines, 1))\n",
    "    first = True\n",
    "    idx = 0\n",
    "    fh.seek(0)\n",
    "    for csvrow in csvreader:\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            groundtruth_array[idx] = float(csvrow[groundtruth_idx])\n",
    "            predictions_array[idx] = float(csvrow[prediction_idx])\n",
    "            idx += 1\n",
    "    # assign an index to seriesuids\n",
    "    for idx in range(len(seriesuids)):\n",
    "        seriesuid = seriesuids[idx]\n",
    "        seriesuids_array[idx] = unique_seriesuids.index(seriesuid)\n",
    "    # compute actual values\n",
    "    nthresholds = len(thresholds)\n",
    "    sensitivities = np.zeros((nthresholds, 1))\n",
    "    fps_per_scan = np.zeros((nthresholds, 1))\n",
    "    nseriesuids = len(unique_seriesuids)\n",
    "    # compute froc\n",
    "    for th in range(nthresholds):\n",
    "        # set the threshold\n",
    "        threshold = thresholds[th]\n",
    "        positives = (predictions_array >= threshold)\n",
    "        # compute false positives and sensitivity\n",
    "        npositive = sum(groundtruth_array == 1.0)\n",
    "        tps_this_threshold = sum(positives[groundtruth_array == 1.0])\n",
    "        fps_this_threshold = sum(positives[groundtruth_array == 0.0])\n",
    "        sens_this_threshold = float(tps_this_threshold)/float(npositive)\n",
    "        sensitivities[th] = sens_this_threshold\n",
    "        fps_per_scan[th] = float(fps_this_threshold)/float(nseriesuids)\n",
    "    fps_per_scan = np.vstack((np.inf, fps_per_scan, -np.inf))\n",
    "    sensitivities = np.vstack((sensitivities[0], sensitivities, sensitivities[-1]))\n",
    "    # save results as csv file, used to compare the two curves later\n",
    "    ho = open(datafilename, 'w')\n",
    "    for i in range(len(fps_per_scan)):\n",
    "        ho.write(str(fps_per_scan[i][0])+','+str(candidateDetectionSensitivity*sensitivities[i][0])+'\\n')\n",
    "    ho.close()\n",
    "    # plot curve\n",
    "    plt.figure()\n",
    "    plt.plot(fps_per_scan, candidateDetectionSensitivity*sensitivities, linewidth=3)\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Average number of false positives per scan')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('FROC Analysis')\n",
    "    plt.grid(b=True, which='both')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodule detection using 1 view\n",
    "In this section, we will evaluate the performance of the convolutional network trained using only one 2D view of the noudule (the axial view). The network input is a 2D view of the nodule candidate, obtained by cropping the slice in the axial view with a bounding box of 50 mm x 50 mm. Patches are resized to 64x64 pixel. In this example, we will also define functions and variables necessary to train the network, but we will not train the network.\n",
    "\n",
    "First, we point to the data on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelsDir = projectDir+'models/' # where the pre-trained network is located\n",
    "modelPath  = modelsDir + '1View.pkl' # pre-trained network, it contains the parameters\n",
    "outputPath = modelsDir + 'output_1_view.csv' # file containing classification results\n",
    "print \"model file: \" + modelPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following network:\n",
    "\n",
    "- convolutional layer (parameters w1), with ReLU non linearity\n",
    "- max pooling\n",
    "- convolutional layer (parameters w2), with ReLU non linearity\n",
    "- max pooling\n",
    "- convolutional layer (parameters w3), with ReLU non linearity\n",
    "- max pooling\n",
    "- fully-connected layer (parameters w4) (with dropout applied for regularization purposes)\n",
    "- softmax layer (parameters w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses the variables to define the model\n",
    "def model_1view(X, w1, w2, w3, w4, w_o, p_drop_hidden):\n",
    "    '''\n",
    "    '''\n",
    "    l1a = rectify(conv2d(X, w1, border_mode='valid')) #border_mode='full'\n",
    "    l1  = max_pool_2d(l1a, (2, 2))\n",
    "    \n",
    "    l2a = rectify(conv2d(l1, w2))\n",
    "    l2 = max_pool_2d(l2a, (2, 2))\n",
    "    \n",
    "    l3a = rectify(conv2d(l2, w3))\n",
    "    l3b = max_pool_2d(l3a, (2, 2))    \n",
    "    l3  = T.flatten(l3b, outdim=2)\n",
    "\n",
    "    l4  = rectify(T.dot(l3, w4))\n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "    \n",
    "    pyx = softmax(T.dot(l4, w_o))\n",
    "    return l1, l2, l3, pyx, l1a, l2a, l3a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we need to initialize the parameters of the network.\n",
    "In this example, we only use weights without biases.\n",
    "The weights are initialized with random values by the function init_weights() defined above.\n",
    "\n",
    "We also need to initialize a variable X which will represent our test data.\n",
    "The type ftensor4() is specific for the Theano library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define weights and input data symbolic variables for 1 view convnet\n",
    "w1_1view = init_weights((24, 1, 5, 5))\n",
    "w2_1view = init_weights((32, 24, 3, 3))\n",
    "w3_1view = init_weights((48, 32, 3, 3))\n",
    "w4_1view = init_weights((48 * 6 * 6, 16))\n",
    "w_o_1view = init_weights((16, 2))\n",
    "X = T.ftensor4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass the defined variable to the model function, and define the theano function that takes X as input and return the prediction, as well as the internal feature maps l1a, l2a, l3a and the weights w1, w2, w3, which we will use for visualization purpose later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_1view, l2_1view, l3_1view, py_x_1view, l1a_1view, l2a_1view, l3a_1view = model_1view(X, w1_1view, w2_1view, w3_1view, w4_1view, w_o_1view, 0.0)\n",
    "y_x_soft_1view = py_x_1view # little abuse of notation\n",
    "predictSoft_1view = theano.function(inputs=[X], outputs=[y_x_soft_1view, l1a_1view, l2a_1view, l3a_1view, w1_1view, w2_1view, w3_1view], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will not train the network, it would take too long.\n",
    "Since we already trained the network beforehand, we can load the trained weights and use the network to classify candidates. The following code is for loading the weights into memory. The pre-trained model has been saved as pkl file and can be loaded from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel_1view(modelPath):\n",
    "    saved_file = open(modelPath, 'rb')\n",
    "    w1_1view.set_value(cPickle.load(saved_file), borrow=True)\n",
    "    w2_1view.set_value(cPickle.load(saved_file), borrow=True)\n",
    "    w3_1view.set_value(cPickle.load(saved_file), borrow=True)\n",
    "    w4_1view.set_value(cPickle.load(saved_file), borrow=True)\n",
    "    w_o_1view.set_value(cPickle.load(saved_file), borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "loadModel_1view(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the weights are loaded, we can visualize them.\n",
    "For this purpose, we first define a function arrangeMaps, that takes a 4D matrix and re-arrange its content into a big square matrix, for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arrangeMaps(x,nPerRow):\n",
    "    nchannels,nfilters,nr,nc = np.shape(x)\n",
    "    nmatrices = nchannels*nfilters\n",
    "    x = np.reshape(x,(nmatrices,nr,nc))\n",
    "    nrMatrix = int(nr*np.ceil((float(nchannels*nfilters)/float(nPerRow))))\n",
    "    ncMatrix = int(nPerRow*nc)\n",
    "    nPerCol = int(nrMatrix/nr)\n",
    "    xmap = np.inf*np.ones((nrMatrix + nPerCol-1, ncMatrix + nPerRow-1))\n",
    "    xmapIdx = 0\n",
    "    for i in range(0,nPerCol):\n",
    "        for j in range(0,nPerRow):\n",
    "            if xmapIdx < nmatrices:\n",
    "                xmap[i*nr+i:(i+1)*nr+i, j*nc+j:(j+1)*nc+j] = np.squeeze(x[xmapIdx,:,:])\n",
    "                xmapIdx += 1\n",
    "    return xmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights of the first convolutional layer (w1_1view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 6, 6\n",
    "w1 = w1_1view.get_value().swapaxes(0,1)\n",
    "print 'filter size: '+str(w1.shape)\n",
    "print 'number of filters: '+str(w1.shape[0] * w1.shape[1])\n",
    "w1_fig = arrangeMaps(w1,nPerRow=int(np.ceil(math.sqrt(w1.shape[0]*w1.shape[1]))))\n",
    "plt.imshow(w1_fig, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values in white are positive, values in black are negative, values in gray are (close to) zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights of the second convolutional layer (w2_1view) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "w2 = w2_1view.get_value().swapaxes(0,1)\n",
    "print 'filter size: '+str(w2.shape)\n",
    "print 'number of filters: '+str(w2.shape[0] * w2.shape[1])\n",
    "w2_fig = arrangeMaps(w2,nPerRow=int(np.ceil(math.sqrt(w2.shape[0]*w2.shape[1]))))\n",
    "plt.imshow(w2_fig, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights of the third convolutional layer (w3_1view) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "w3 = w3_1view.get_value().swapaxes(0,1)\n",
    "print 'filter size: '+str(w3.shape)\n",
    "print 'number of filters: '+str(w3.shape[0] * w3.shape[1])\n",
    "w3_fig = arrangeMaps(w3,nPerRow=int(np.ceil(math.sqrt(w3.shape[0]*w3.shape[1]))))\n",
    "plt.imshow(w3_fig, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "You may notice that some filters have most of their values close to zero. What can we do to avoid that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize feature maps and classification output\n",
    "\n",
    "Now we can use the pre-trained network to classify the data set containing one view for each candidate.\n",
    "For this example, we used ~1/5 of the LIDC-IDRI data set, in a five-fold cross-validation fashion.\n",
    "The pre-trained network was trained using candidated in the other 4 folds, 3 folds for training, 1 fold for validation, and some data augmentation was used.\n",
    "\n",
    "The detection of candidates is part of an ongoing research project, which gives a candidate detection sensitivity of 0.944. In this example, we will not run rhe network on the whole test data set (>2GB), since it takes several minutes. We did it beforehand, and we stored the classification output in a csv file (output_1_view.csv), that we can load to compute the ROC and FROC curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function classifyDataset_1plane takes a dataset file and a pre-trained network as input, and classifies the candidates. The results are stored as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifyDataset_1plane(datasetPath, modelPath, outputPath, showFig=False, nExamples=np.inf):\n",
    "    dsX,dsY,dsPos,dsImage = getDataset(datasetPath, allInfo = True)    \n",
    "    dsX = dsX.reshape(-1, 1, 64, 64)    \n",
    "    res = open(outputPath,'w')\n",
    "    res.write('f_0,o_0,o_1,o_2,i_seriesuid,i_worldVectorX,i_worldVectorY,i_worldVectorZ\\n')\n",
    "    for i in range(min(len(dsX), nExamples)):\n",
    "        if i % 1000 == 0:\n",
    "            print \"Progress = \" + str(100*float(i)/len(dsX)) + \"%\"\n",
    "        xcoord = dsPos[i][0]\n",
    "        ycoord = dsPos[i][1]\n",
    "        zcoord = dsPos[i][2]\n",
    "        img    = dsImage[i]\n",
    "        y = dsY[i][1]\n",
    "        imarray = [dsX[i,:,:,:]]\n",
    "        pred,l1a,l2a,l3a,w1,w2,w3 = predictSoft_1view(imarray)\n",
    "        # show image with classification steps\n",
    "        if showFig:\n",
    "            showClassification(imarray,[l1a,l2a,l3a],[w1,w2,w3],pred,y)\n",
    "        res.write('0,'+str(dsY[i][1])+','+str(pred[0][0])+','+str(pred[0][1])+','+img+','+str(xcoord)+','+str(ycoord)+','+str(zcoord)+'\\n')\n",
    "    res.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better uderstand the performance of the network, we visualize the input patch, the three internal feature maps and the final prediction. For this purpose, we made a small data set containing 100 nodules and 100 false positives. By the default, the number of examples to show is nExamples=10, but you can increase it up to nExamples=200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def showClassification(imarray,featMaps,weights,prediction,y):\n",
    "    nFeatMaps = len(featMaps)\n",
    "    img = np.squeeze(imarray)\n",
    "    # show input image\n",
    "    plt.subplot(1,nFeatMaps+2,1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if y == 0:\n",
    "        plt.title('non nodule')\n",
    "    else:\n",
    "        plt.title('nodule')\n",
    "    # show feature maps\n",
    "    for i in range(nFeatMaps):\n",
    "        plt.subplot(1,nFeatMaps+2,2+i)\n",
    "        fmap = arrangeMaps(featMaps[i],nPerRow=int(np.ceil(math.sqrt(featMaps[i].shape[0] * featMaps[i].shape[1]))))\n",
    "        plt.imshow(fmap, cmap='jet',interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title('C'+str(i+1)+'')\n",
    "    # show prediction\n",
    "    plt.subplot(1,nFeatMaps+2,nFeatMaps+2)\n",
    "    pos = range(len(prediction.flatten()))\n",
    "    plt.bar(pos, prediction.flatten(), width=1)\n",
    "    plt.xticks([0.5,1.5], ('non nodule', 'nodule'))\n",
    "    plt.title('prediction')\n",
    "    plt.show()\n",
    "    \n",
    "# classify\n",
    "datasetDir = projectDir+'/data/'\n",
    "modelsDir = projectDir+'/models/'\n",
    "testPath  = datasetDir + '1ViewTestset_small.npz'\n",
    "modelPath  = modelsDir + '1View.pkl'\n",
    "outputPath = modelsDir + 'output_1_view_small.csv'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 16, 2.5\n",
    "\n",
    "classifyDataset_1plane(testPath, modelPath, outputPath, showFig=True, nExamples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "ROC analysis on 1/5 of the LIDC-IDRI data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute ROC curve\n",
    "plt.rcParams['figure.figsize'] = 6, 6\n",
    "inputfile = modelsDir + 'output_1_view.csv'\n",
    "computeROC(inputfile, 'ROC - one patch per nodule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FROC curve\n",
    "Computing the FROC curve takes a bit more than the ROC curve.\n",
    "To speed up the computation, you can reduce the value in npoints, which indicates how many threshold values we consider to compute FPs/scan.\n",
    "\n",
    "Note that the value of 'candidateDetectionSensitivity' is also passed as a parameter.\n",
    "We have to take into account for the candidate detection sensitivity, which is the maximum we can get, because some nodules in the scan might not be in the set of candidates.\n",
    "If we did not consider it, the FROC curve will get up to a sensitivity of 1.0, since all the nodule candidates will be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute FROC\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "inputfile = modelsDir + 'output_1_view.csv'\n",
    "figurefilename = projectDir+'froc_1_view.pdf'\n",
    "figuretitle = 'FROC - one patch per nodule'\n",
    "candidateDetectionSensitivity = 0.944 # pre-computed\n",
    "datafilename = projectDir+'froc_data_1_view.csv'\n",
    "computeFROC(inputfile, figuretitle, candidateDetectionSensitivity, datafilename, npoints=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Nodule detection using 3 views\n",
    "\n",
    "We repeat the same procedure but for a network that receives three views of the nodule simultaneously, in particular, three patches along the axial, coronal and sagittal view are considered.\n",
    "\n",
    "The architecture consists of three streams of convolutional and max-pooling layers, which share the weights. The final softmax layer is connected to the three fully-connected layers and makes the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelsDir = projectDir+'models/'\n",
    "modelPath  = modelsDir + '3Views.pkl'\n",
    "outputPath = modelsDir + 'output_3_views.csv'\n",
    "rocPath    = modelsDir + 'roc_3_views.csv'\n",
    "print \"model file: \" + modelPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight configuration is exactly the same as the network working on 1 view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define weights and input data symbolic variables for 3 views convnet\n",
    "w1_3views = init_weights((24, 1, 5, 5))\n",
    "w2_3views = init_weights((32, 24, 3, 3))\n",
    "w3_3views = init_weights((48, 32, 3, 3))\n",
    "w4_3views = init_weights((48 * 6 * 6, 16))\n",
    "w_o_3views = init_weights((16, 2))\n",
    "\n",
    "X1 = T.ftensor4()\n",
    "X2 = T.ftensor4()\n",
    "X3 = T.ftensor4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model to work on the three views. The weights are shared, so we use w1 for the first layer in the three streams, w2 for the second layer in the three streams etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_3views(X1, X2, X3, w1, w2, w3, w4, w_o, p_drop_hidden):\n",
    "\n",
    "    # layer 1\n",
    "    l1a_p1 = rectify(conv2d(X1, w1, border_mode='valid'))\n",
    "    l1_p1  = max_pool_2d(l1a_p1, (2, 2))\n",
    "\n",
    "    l1a_p2 = rectify(conv2d(X2, w1, border_mode='valid'))\n",
    "    l1_p2  = max_pool_2d(l1a_p2, (2, 2))\n",
    "\n",
    "    l1a_p3 = rectify(conv2d(X3, w1, border_mode='valid'))\n",
    "    l1_p3  = max_pool_2d(l1a_p3, (2, 2))\n",
    "\n",
    "    # layer 2\n",
    "    l2a_p1 = rectify(conv2d(l1_p1, w2))\n",
    "    l2_p1 = max_pool_2d(l2a_p1, (2, 2))\n",
    "\n",
    "    l2a_p2 = rectify(conv2d(l1_p2, w2))\n",
    "    l2_p2 = max_pool_2d(l2a_p2, (2, 2))\n",
    "\n",
    "    l2a_p3 = rectify(conv2d(l1_p3, w2))\n",
    "    l2_p3 = max_pool_2d(l2a_p3, (2, 2))\n",
    "\n",
    "    # layer 3\n",
    "    l3a_p1 = rectify(conv2d(l2_p1, w3))\n",
    "    l3b_p1 = max_pool_2d(l3a_p1, (2, 2))\n",
    "    l3_p1  = T.flatten(l3b_p1, outdim=2)\n",
    "\n",
    "    l3a_p2 = rectify(conv2d(l2_p2, w3))\n",
    "    l3b_p2 = max_pool_2d(l3a_p2, (2, 2))\n",
    "    l3_p2  = T.flatten(l3b_p2, outdim=2)\n",
    "\n",
    "    l3a_p3 = rectify(conv2d(l2_p3, w3))\n",
    "    l3b_p3 = max_pool_2d(l3a_p3, (2, 2))\n",
    "    l3_p3  = T.flatten(l3b_p3, outdim=2)\n",
    "    \n",
    "    # layer 4\n",
    "    l4_p1 = rectify(T.dot(l3_p1, w4))\n",
    "    l4_p2 = rectify(T.dot(l3_p2, w4))\n",
    "    l4_p3 = rectify(T.dot(l3_p3, w4))\n",
    "    \n",
    "    # concatenate the outputs of 3 fully connected layers\n",
    "    l4 = T.concatenate([l4_p1, l4_p2, l4_p3], axis=1)\n",
    "    \n",
    "    l4 = dropout(l4, p_drop_hidden)\n",
    "    \n",
    "    pyx = softmax(T.dot(l4, w_o))\n",
    "    \n",
    "    return l1_p1, l2_p1, l3_p1, pyx, l1a_p1, l2a_p1, l3a_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 views\n",
    "l1_p1_3views, l2_p1_3views, l3_p1_3views, py_x_3views, l1a_3views, l2a_3views, l3a_3views = model_3views(X1, X2, X3, w1_3views, w2_3views, w3_3views, w4_3views, w_o_3views, 0.0)\n",
    "y_x_soft_3views = py_x_3views\n",
    "predictSoft_3views = theano.function(inputs=[X1, X2, X3], outputs=[y_x_soft_3views, l1a_3views, l2a_3views, l3a_3views, w1_3views, w2_3views, w3_3views], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel_3views(modelPath):\n",
    "    save_file = open(modelPath, 'rb')\n",
    "    w1_3views.set_value(cPickle.load(save_file), borrow=True)\n",
    "    w2_3views.set_value(cPickle.load(save_file), borrow=True)\n",
    "    w3_3views.set_value(cPickle.load(save_file), borrow=True)\n",
    "    w4_3views.set_value(cPickle.load(save_file), borrow=True)\n",
    "    w_o_3views.set_value(cPickle.load(save_file), borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loadModel_3views(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyDataset_3planes(datasetPath, modelPath, outputPath):\n",
    "    dsX,dsY,dsPos,dsImage = getDataset(datasetPath, allInfo = True)\n",
    "    \n",
    "    dsX1 = dsX[:,:,:,0]\n",
    "    dsX1 = dsX1.reshape(-1, 1, 64, 64) \n",
    "    dsX2 = dsX[:,:,:,1]\n",
    "    dsX2 = dsX2.reshape(-1, 1, 64, 64) \n",
    "    dsX3 = dsX[:,:,:,2]\n",
    "    dsX3 = dsX3.reshape(-1, 1, 64, 64) \n",
    "\n",
    "    res = open(outputPath,'w')\n",
    "    res.write('f_0,o_0,o_1,o_2,i_seriesuid,i_worldVectorX,i_worldVectorY,i_worldVectorZ\\n')\n",
    "    for i in range(len(dsX)):\n",
    "        if i % 100 == 0:\n",
    "            print \"Progress = \" + str(100*float(i)/len(dsX)) + \"%\"\n",
    "        xcoord = dsPos[i][0]\n",
    "        ycoord = dsPos[i][1]\n",
    "        zcoord = dsPos[i][2]\n",
    "        img    = dsImage[i]\n",
    "        imarray1 = [dsX1[i,:,:,:]]\n",
    "        imarray2 = [dsX2[i,:,:,:]]\n",
    "        imarray3 = [dsX3[i,:,:,:]]\n",
    "        pred = predictSoft_3views(imarray1,imarray2,imarray3)[0]\n",
    "        res.write('0,'+str(dsY[i][1])+','+str(pred[0][0])+','+str(pred[0][1])+','+img+','+str(xcoord)+','+str(ycoord)+','+str(zcoord)+'\\n')\n",
    "    res.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We do not classify the data set here, as for the example with 1 view, we did it beforehand and saved the classification results in a csv file. Now we evaluate the performance via ROC and FROC analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute ROC\n",
    "plt.rcParams['figure.figsize'] = 6, 6\n",
    "inputfile = outputPath\n",
    "figurefilename = projectDir+'roc_3_views.pdf'\n",
    "figuretitle = 'ROC - three patches per nodule'\n",
    "computeROC(inputfile, figuretitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute FROC\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "figurefilename = projectDir+'froc_3_views.pdf'\n",
    "figuretitle = 'FROC - three patches per nodule'\n",
    "candidateDetectionSensitivity = 0.944 # pre-computed\n",
    "datafilename = projectDir+'froc_data_3_views.csv'\n",
    "computeFROC(inputfile, figuretitle, candidateDetectionSensitivity, datafilename, npoints=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One view versus three views\n",
    "\n",
    "Now we plot the two FROC together, to compare the performance of the approach with one view versus the one with three views. We do not compute the FROC curves again, but simply load the csv files previously saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "datafilename1 = modelsDir+'froc_data_1_view.csv'\n",
    "datafilename3 = modelsDir+'froc_data_3_views.csv'\n",
    "froc1 = open(datafilename1,'r').readlines()\n",
    "froc3 = open(datafilename3,'r').readlines()\n",
    "x1 = []; y1 = []\n",
    "x3 = []; y3 = []\n",
    "for line in froc1:\n",
    "        xy = line.rstrip().split(',')\n",
    "        x1.append(float(xy[0])); y1.append(float(xy[1]))\n",
    "for line in froc3:\n",
    "        xy = line.rstrip().split(',')\n",
    "        x3.append(float(xy[0])); y3.append(float(xy[1]))\n",
    "plt.figure()\n",
    "froc1, = plt.plot(x1, y1, linewidth=3, color='red')\n",
    "froc3, = plt.plot(x3, y3, linewidth=3, color='green')\n",
    "plt.xscale('log')\n",
    "plt.yscale('linear')\n",
    "plt.xlabel('Average number of false positives per scan')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('FROC Analysis')\n",
    "plt.grid(b=True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.legend([froc1, froc3],['1 view','3 views'],loc=4,prop={'size':12})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
